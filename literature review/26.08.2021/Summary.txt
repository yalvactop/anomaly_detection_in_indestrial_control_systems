## Fence GAN: Towards Better Anomaly Detection - 2019

The traditional GAN loss is not directly aligned with the anomaly detection objective: it encourages the distribution of the generated samples to overlap with the real data and so the resulting discriminator has been found to be ineffective as an anomaly detector.The traditional GANs generate samples over the whole data distribution.
They propose simple modifications to the GAN loss such that the generated samples lie at the boundary of the real data distribution. 
Generator Loss:
Dispersion loss which maximizes distance of the generated data points from their centre of mass, encourages the generated points to cover the whole boundary. Otherwise because of the Encirclement Loss all the points can gather at the same point on the boundy.
With the modified GAN loss, FGAN directly uses the discriminator score as an anomaly threshold where they prioritize classifying the real data points correctly rather than classifying generated data correctly. If the discriminator focuses more on classifying generated data correctly, then the discriminator will start to classify real data as generated data. Thus, the loss function of the discriminator should be modified to prioritise classifying real data correctly. So it does not rely on the reconstruction loss. They use MNIST, CIFAR10 and KDD99 datasets

## EFFICIENT GAN-BASED ANOMALY DETECTION - 2018

They leverage recently developed GAN methods that simultaneously learn an encoder during training to develop an anomaly detection method that is efficient at test time. This enables to avoid the computationally expensive step of recovering a latent representation at test time. Unlike in a regular GAN where the discriminator only considers inputs (real or generated), the discriminator D in this context also considers the latent representation.
They use (MNIST) (LeCun et al., 1998) and a network intrusion dataset (KDD99 10percent)

## Anomaly Detection in Cyber Physical Systems using Recurrent Neural Networks - 2017

They propose the use of a Long Short Term Memory Recurrent Neural Network for learning the temporal behaviour of the data in CPSs and using Cumulative Sum (CUSUM) for anomaly detection in this domain. LSTM-RNN as a predicts the normal behaviour and, the Cumulative Sum method to identify abnormal behaviours.
SWaT consists of seven days of normal continuous operation and four days with attack. A total of thirty-six attacks were conducted during the four days, and is the most updated and complex open source dataset: Single Stage Multi Point, Multi Stage Single Point, Multi Stage Multi Point. Due to the vast amount of data, they could not train al the sensors data.

## Anomaly Detection with Generative Adversarial Networks for Multivariate Time Series - 2019

They propose a novel Generative Adversarial Networks-based Anomaly Detection (GAN-AD) method for complex networked CPSs. Instead of treating each sensor’s and actuator’s time series independently, they model the time series of multiple sensors and actuators in the CPS concurrently to take into account of potential latent interactions between them. To exploit both the generator and the discriminator of the GAN, the GAN-trained discriminator is deployed together with the residuals between generator-reconstructed data and the actual samples to detect possible anomalies in the complex CPS.
In the future, they plan to further research on feature selection for multivariate anomaly detection, and investigate principled methods for choosing the latent dimension and PC dimension with theoretical guarantees.

## Anomaly Detection for a Water Treatment System Using Unsupervised Machine Learning - 2017

They compare two methods: Deep Neural Networks (LSTM) adapted to time series data generated by a CPS, and one-class Support Vector Machines (SVM). Both methods are trained a log generated by SWaT and they implemented 36 different attack scenarios using the same log. LSTM has higher F measure where SVM has slightly better recall. Both methods have difficulties in detecting gradual changes of sensor values and anomalous actuator behavior. They are planning to use SWaT simulator.

## Adversarially Learned Anomaly Detection - 2018

Adversarially Learned Anomaly Detection (ALAD) based on bi-directional GANs derives adversarially learned features for the anomaly detection task. ALAD then uses reconstruction errors based on these adversarially learned features to determine if a data sample is anomalous. ALAD builds on recent advances to ensure data-space and latent-space cycle-consistencies and stabilize GAN training, which results in significantly improved anomaly detection performance.
Anomaly score calculation is similar to feature matching loss. They use en encoder which learns mapping from data space to latent space during training. That improves performance during test. The additional discriminitor to improve the encoder and spectral normalization have stabilized GAN training and improved preformance.
It is experimented using image and tabular datasets.

## A GAN-Based Anomaly Detection Approach for Imbalanced Industrial Time Series - 2019

Support vector machine and convolutional neural networks are struggling to attain high classication accuracies for class-imbalanced problems, because they tend to ensure the accuracy of the majority class.
An encoder-decoder-encoder three-sub-network generator is trained involving the elaborately extracted features from normal samples alone.
To reduce training time and increase diagnosis performance, a feature extractor is inserted between the original data and GAN.
Apparent loss and latent loss are used to improve accuracy. Latent loss compares the latent data in between encoder and decoder with the output of the last encoder. Apparent(discriminator) loss compares the input data with the output of the decoder data. Fraud loss promotes the generator to generate fake samples as real samples as possible to fool the discriminator.
To reduce the size of training data and save computational time, feature extractor is employed to explore the most representative q features. Based on the principle of universality, they select 16 most representative features which any time series can be encapsulated into.
Rolling bearing data from CWRU is used.

## General Summary

Feature extraction is very important in terms of neural networks performance. In addition, many other dimension manupilation techniques are used in the articles. GAN approach seems useful for multidimensional data with many sensor and actuators.
For multivariate data, sliding window approach is used due to easier training and technological limitations. 
LSTM-RNN is generally the choice of network architecture because of the ability to analyze the time series data.
Calculation of anomaly score differ from paper to paper. Some use only generator loss, some use the combination of generator and discriminator loss, some create additional loss calculation training an encoder or some us LSTM for prediction to use CUSUM for classification.
All the papers claim that they are the state-of-art which makes it difficult for me to find the optimum technique.
In the last arcticles I read, I tried to pay more attention on the feature extraction techniques and the implementation of loss functions. Even though authors almost always mentions the importance of the feature extraction techniques as a future research, they don't reserve too much space in their paper.
Each paper compare their work with other papers however these comparisons are not sequential. In another word, I was able to see a new comparison benchmark in each paper which makes it difficult to order them. This might be because the papers are not written in the same year so they get old too fast. For remaining part of my literature research, I am plannnig to consider only the papers released after 2020 so that I can compare the technologies in a consistent  way. 
SWaT simulator can be useful in my project.